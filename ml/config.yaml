common:
  seed: 12345
  batch_size: 4
  learning_rate: 0.000025
  num_train_epochs: 10
  dataset_path: /opt/ml/final-project-level3-nlp-10/ml/data/project_dataset
  gzip: True
wandb:
  #project_name: Final_FiD_train
  project_name: Final_FiD_trail
  entity_name: boost2end
dpr:
  #emb_type: train # [train, valid, all] 중 어떤 dataset으로 embedding passage들을 사용할 지 선택.
  emb_train_path: /opt/ml/final-project-level3-nlp-10/ml/data/dense_embeddings/project_Em/train/
  emb_valid_path: /opt/ml/final-project-level3-nlp-10/ml/data/dense_embeddings/project/valid/san_with_project
  emb_all_path: /opt/ml/final-project-level3-nlp-10/ml/data/dense_embeddings/project/all/san_with_project
  encoder_tokenizer: klue/bert-base
  model_name: klue/bert-base
  do_eval: True
  eval:
    p_encoder_path: model/saved_models/klue_bert-base/p_encoder
    q_encoder_path: model/saved_models/klue_bert-base/q_encoder
  train:
    neg_num: 7

fid:
  encoder_tokenizer: klue/bert-base
  continue_learning: True
  checkpoint_path: /opt/ml/final-project-level3-nlp-10/ml/model/saved_models/fid/mecab_newDPR_topk10/pretrained_last
  model_save_path: model/saved_models/fid/mecab_newDPR_topk10_epoch20
  reader_model: alaggung/bart-r3f
  topk: 10
  t5_reader_model: KETI-AIR/ke-t5-large